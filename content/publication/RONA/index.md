---
title: 'RONA: Pragmatically Diverse Image Captioning with Coherence Relations'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - "<b>Aashish Anantha Ramakrishnan</b>"
  - Aadarsh Anantha Ramakrishnan
  - Dongwon Lee

# Author notes (optional)
# author_notes:
#   - 'Equal contribution'
#   - 'Equal contribution'

date: '2025-03-14T00:00:00Z'
doi: 'https://doi.org/10.48550/arXiv.2503.10997'

# Schedule page publish date (NOT publication's date).
# publishDate: '2017-01-01T00:00:00Z'

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ['paper-conference']

# Publication name and optional abbreviated publication name.
publication: In *The Fourth Workshop on Intelligent and Interactive Writing Assistants (In2Writing)*
publication_short: In *NAACL-W In2Writing 2025*

abstract: "Writing Assistants (e.g., Grammarly, Microsoft Copilot) traditionally generate diverse image captions by employingsyntactic and semantic variations to describe image components. However, human-written captions prioritize conveying a central message alongside visual descriptions using pragmatic cues. To enhance pragmatic diversity, it is essential to explore alternative ways of communicating these messages in conjunction with visual content. To address this challenge, we propose RONA, a novel prompting strategy for Multi-modal Large Language Models (MLLM) that leverages Coherence Relations as an axis for variation. We demonstrate that RONA generates captions with better overall diversity and ground-truth alignment, compared to MLLM baselines across multiple domains. Our code is available at: https://github.com/aashish2000/RONA"

# Summary. An optional shortened abstract.
summary: "Writing assistants like Grammarly and Microsoft Copilot typically generate diverse image captions through syntactic and semantic variation. In contrast, human-written captions rely on pragmatic cues to convey a central message. To better capture this pragmatic diversity, we introduce RONA, a prompting strategy for Multi-modal Large Language Models (MLLMs) that uses Coherence Relations as a variation axis. RONA produces more diverse and accurate captions than standard MLLM baselines across domains. Code: https://github.com/aashish2000/RONA"

tags: []

# Display this page in the Featured widget?
featured: false

# Custom links (uncomment lines below)
links:
- name: Arxiv
  url: https://www.arxiv.org/abs/2503.10997

# url_pdf: ''
url_code: 'https://github.com/aashish2000/RONA'
# url_dataset: https://zenodo.org/records/10974908
# url_poster: ''
# url_project: ''
# url_slides: ''
# url_source: 'https://github.com/HugoBlox/hugo-blox-builder'
# url_video: 'https://youtube.com'

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# image:
  # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  # focal_point: ''
  # preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
# projects:
#   - example

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
# slides: example
---
